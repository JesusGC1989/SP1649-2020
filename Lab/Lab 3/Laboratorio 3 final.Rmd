---
title: "Labaratorio 3 respuestas"
author: "Jesús Guzmán Castillo"
date: "12/10/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache= TRUE, warning = FALSE)
```

# **Métodos de interpolación no geoestadísticos**

Los métodos de interpolación no geoestadísticos son aquellos métodos espaciales que buscan realizar interpolación pero no modelan la correlación espacial. En este caso, se tienen los métodos de  Interpolación don pesos de distancia inversa, la regresión lineal, o los métodos proximidad de polígonos, entre otros. 

## Datos de precipitación en el Estado de California. 
 **Introducción**
Para esta primera sección se utilizarán los datos de precipitación del Estado de California.

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
if (!require("rspatial")) devtools::install_github('rspatial/rspatial')
library(rspatial)
d <- sp_data('precipitation')
head(d)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
d$prec <- rowSums(d[, c(6:17)])
plot(sort(d$prec), ylab='Annual precipitation (mm)', las=1, xlab='Stations')
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
library(sp)
dsp <- SpatialPoints(d[,4:3], proj4string=CRS("+proj=longlat +datum=NAD83"))
dsp <- SpatialPointsDataFrame(dsp, d)
CA <- sp_data("counties")
# define groups for mapping
cuts <- c(0,200,300,500,1000,3000)
# set up a palette of interpolated colors
blues <- colorRampPalette(c('yellow', 'orange', 'blue', 'dark blue'))
pols <- list("sp.polygons", CA, fill = "lightgray")
spplot(dsp, 'prec', cuts=cuts, col.regions=blues(5), sp.layout=pols, pch=20, cex=2)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
TA <- CRS("+proj=aea +lat_1=34 +lat_2=40.5 +lat_0=0 +lon_0=-120 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=m +ellps=GRS80 +towgs84=0,0,0")
library(rgdal)
dta <- spTransform(dsp, TA)
cata <- spTransform(CA, TA)
```
 
```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
RMSE <- function(observed, predicted) {
  sqrt(mean((predicted - observed)^2, na.rm=TRUE))
}

null <- RMSE(mean(dsp$prec), dsp$prec)
null


```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
library(dismo)
v <- voronoi(dta)
plot(v)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
ca <- aggregate(cata)
vca <- intersect(v, ca)
spplot(vca, 'prec', col.regions=rev(get_col_regions()))
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
r <- raster(cata, res=10000)
vr <- rasterize(vca, r, 'prec')
plot(vr)
```


## Pregunta 1.
**Describe what each step in the code chunk does**

```{r, echo=TRUE, cache= TRUE}
set.seed(5132015)
kf <- kfold(nrow(dta))
rmse <- rep(NA, 5)
for (k in 1:5) {
  test <- dta[kf == k, ]
  train <- dta[kf != k, ]
  v <- voronoi(train)
  p <- extract(v, test)
  rmse[k] <- RMSE(test$prec, p$prec)
}
rmse
mean(rmse)
1 - (mean(rmse) / null)

```

En este chunk de programa una validación cruzada para la función de interpolación mediante polígonos de proximidad. En este caso, se hace con una base de *training* y una base de *testing*, y se calcula el rmsea comparando los valores predichos del modelo entrenado con los datos de *testing*, versus los datos reales en la base de *testing*.
Al final, se calcula su media y se compara con el modelo nulo, el cual se calculo anteriormente. El modelo nulo se trata de interpolar únicamente con la media.

## Pregunta 2
**How does the proximity-polygon approach compare to the NULL model?**

Como se observa, la razón del RMSEA entre ambos modelos es de 0.5479875, con lo que se concluye que es mejor la interpolación con la función de polígonos de proximidad.

## Pregunta 3

**You would not typically use proximty polygons for rainfall data. For what kind of data would you use them?**

Probablemente lo usaría para datos de tipo categóricos u ordinales, no para datos contínuos, como es la lluvia.


```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
library(gstat)
gs <- gstat(formula=prec~1, locations=dta, nmax=5, set=list(idp = 0))
nn <- interpolate(r, gs)
## [inverse distance weighted interpolation]
nnmsk <- mask(nn, vr)
plot(nnmsk)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
rmsenn <- rep(NA, 5)
for (k in 1:5) {
  test <- dta[kf == k, ]
  train <- dta[kf != k, ]
  gscv <- gstat(formula=prec~1, locations=train, nmax=5, set=list(idp = 0))
  p <- predict(gscv, test)$var1.pred
  rmsenn[k] <- RMSE(test$prec, p)
}
## [inverse distance weighted interpolation]
## [inverse distance weighted interpolation]
## [inverse distance weighted interpolation]
## [inverse distance weighted interpolation]
## [inverse distance weighted interpolation]
rmsenn
## [1] 200.6222 190.8336 180.3833 169.9658 237.9067
mean(rmsenn)
## [1] 195.9423
1 - (mean(rmsenn) / null)
## [1] 0.5498908
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
library(gstat)
gs <- gstat(formula=prec~1, locations=dta)
idw <- interpolate(r, gs)
## [inverse distance weighted interpolation]
idwr <- mask(idw, vr)
plot(idwr)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
rmse <- rep(NA, 5)
for (k in 1:5) {
  test <- dta[kf == k, ]
  train <- dta[kf != k, ]
  gs <- gstat(formula=prec~1, locations=train)
  p <- predict(gs, test)
  rmse[k] <- RMSE(test$prec, p$var1.pred)
}
## [inverse distance weighted interpolation]
## [inverse distance weighted interpolation]
## [inverse distance weighted interpolation]
## [inverse distance weighted interpolation]
## [inverse distance weighted interpolation]
rmse
## [1] 215.3319 211.9383 190.0231 211.8308 230.1893
mean(rmse)
## [1] 211.8627
1 - (mean(rmse) / null)
## [1] 0.5133192
```

## Pregunta 4

**IDW generated rasters tend to have a noticeable artefact. What is that?**



Con este método, pareciera que la interpolación muestra una concentración, pues hacia el norte la intensidad de la precipitación se ve mayor, mientras que hacie el sur se ve una precipitación mucho menor. Si bien es cierto al observar el mapa 1 se muestra que esto es cierto, en el sur-oeste se observa que hay mayor precipitación que la observada en el mapa con la interpolación IDW.
Los artefactos son los puntos en blanco, que son los puntos en donde se tienen mediciones, por lo que no se debe interpolar. 

## Pregunta 5

**Inspect the arguments used for and make a map of the IDW model below. What other name could you give to this method (IDW with these parameters)? Why?**

```{r}
gs2 <- gstat(formula=prec~1, locations=dta, nmax=1, set=list(idp=1))

```
En este caso el idp al ser únicamente estaría usando el inverso, no elevaría a ninguna potencia para construir los pesos. Por ende,yo lo llamaría interpolación por pesos simples de distancia


#Interpolación con métodos geoestadísticos

Los modelos geoestadísticos son aquellos que queremos ver la asociacion entre la variable respuesta y su distancia. Se busca modelar la correlación entre los puntos y la variable respuesta. 

## Datos de contaminación del aire en California
Para esta sección se utilizará como variable respuesta la contaminación del aire en el estado de California.


```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
library(rspatial)
x <- sp_data("airqual")
x$OZDLYAV <- x$OZDLYAV * 1000
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
library(sp)
coordinates(x) <- ~LONGITUDE + LATITUDE
proj4string(x) <- CRS('+proj=longlat +datum=NAD83')
TA <- CRS("+proj=aea +lat_1=34 +lat_2=40.5 +lat_0=0 +lon_0=-120 +x_0=0 +y_0=-4000000 +datum=NAD83 +units=km +ellps=GRS80")
library(rgdal)
aq <- spTransform(x, TA)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
cageo <- sp_data('counties.rds')
ca <- spTransform(cageo, TA)
r <- raster(ca)
res(r) <- 10  # 10 km if your CRS's units are in km
g <- as(r, 'SpatialGrid')
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
library(gstat)
gs <- gstat(formula=OZDLYAV~1, locations=aq)
v <- variogram(gs, width=20)
head(v)
##     np      dist    gamma dir.hor dir.ver   id
## 1 1010  11.35040 34.80579       0       0 var1
## 2 1806  30.63737 47.52591       0       0 var1
## 3 2355  50.58656 67.26548       0       0 var1
## 4 2619  70.10411 80.92707       0       0 var1
## 5 2967  90.13917 88.93653       0       0 var1
## 6 3437 110.42302 84.13589       0       0 var1
plot(v)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
fve <- fit.variogram(v, vgm(85, "Exp", 75, 20))
fve
##   model    psill    range
## 1   Nug 21.96600  0.00000
## 2   Exp 85.52957 72.31404
plot(variogramLine(fve, 400), type='l', ylim=c(0,120))
points(v[,2:3], pch=20, col='red')
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
fvs <- fit.variogram(v, vgm(85, "Sph", 75, 20))
fvs
##   model    psill    range
## 1   Nug 25.57019   0.0000
## 2   Sph 72.65881 135.7744
plot(variogramLine(fvs, 400), type='l', ylim=c(0,120) ,col='blue', lwd=2)
points(v[,2:3], pch=20, col='red')
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
plot(v, fve)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
k <- gstat(formula=OZDLYAV~1, locations=aq, model=fve)
# predicted values
kp <- predict(k, g)
## [using ordinary kriging]
spplot(kp)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
# variance
ok <- brick(kp)
ok <- mask(ok, ca)
names(ok) <- c('prediction', 'variance')
plot(ok)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
library(gstat)
idm <- gstat(formula=OZDLYAV~1, locations=aq)
idp <- interpolate(r, idm)
## [inverse distance weighted interpolation]
idp <- mask(idp, ca)
plot(idp)
```


## Pregunta 6

**Which method performed best?**

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
RMSE <- function(observed, predicted) {
  sqrt(mean((predicted - observed)^2, na.rm=TRUE))
}
f1 <- function(x, test, train) {
  nmx <- x[1]
  idp <- x[2]
  if (nmx < 1) return(Inf)
  if (idp < .001) return(Inf)
  m <- gstat(formula=OZDLYAV~1, locations=train, nmax=nmx, set=list(idp=idp))
  p <- predict(m, newdata=test, debug.level=0)$var1.pred
  RMSE(test$OZDLYAV, p)
}
set.seed(20150518)
i <- sample(nrow(aq), 0.2 * nrow(aq))
tst <- aq[i,]
trn <- aq[-i,]
opt <- optim(c(8, .5), f1, test=tst, train=trn)
opt
```

De los tres métodos el que tiene un mejor ajuste según  el RMSEA es el método de Kriging, pues el método número 4 es de consenso entre los diversos métodos.


```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
m <- gstat(formula=OZDLYAV~1, locations=aq, nmax=opt$par[1], set=list(idp=opt$par[2]))
idw <- interpolate(r, m)
## [inverse distance weighted interpolation]
idw <- mask(idw, ca)
plot(idw)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
library(fields)
m <- Tps(coordinates(aq), aq$OZDLYAV)
tps <- interpolate(r, m)
tps <- mask(tps, idw)
plot(tps)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
library(dismo)
nfolds <- 5
k <- kfold(aq, nfolds)
ensrmse <- tpsrmse <- krigrmse <- idwrmse <- rep(NA, 5)
for (i in 1:nfolds) {
  test <- aq[k!=i,]
  train <- aq[k==i,]
  m <- gstat(formula=OZDLYAV~1, locations=train, nmax=opt$par[1], set=list(idp=opt$par[2]))
  p1 <- predict(m, newdata=test, debug.level=0)$var1.pred
  idwrmse[i] <-  RMSE(test$OZDLYAV, p1)
  m <- gstat(formula=OZDLYAV~1, locations=train, model=fve)
  p2 <- predict(m, newdata=test, debug.level=0)$var1.pred
  krigrmse[i] <-  RMSE(test$OZDLYAV, p2)
  m <- Tps(coordinates(train), train$OZDLYAV)
  p3 <- predict(m, coordinates(test))
  tpsrmse[i] <-  RMSE(test$OZDLYAV, p3)
  w <- c(idwrmse[i], krigrmse[i], tpsrmse[i])
  weights <- w / sum(w)
  ensemble <- p1 * weights[1] + p2 * weights[2] + p3 * weights[3]
  ensrmse[i] <-  RMSE(test$OZDLYAV, ensemble)
}
rmi <- mean(idwrmse)
rmk <- mean(krigrmse)
rmt <- mean(tpsrmse)
rms <- c(rmi, rmt, rmk)
rms
## [1] 8.041305 8.307235 7.930799
rme <- mean(ensrmse)
rme
## [1] 7.858051
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
weights <- ( rms / sum(rms) )
s <- stack(idw, ok[[1]], tps)
ensemble <- sum(s * weights)
```

```{r, echo=FALSE, hide=TRUE, cache= TRUE, include=FALSE}
s <- stack(idw, ok[[1]], tps, ensemble)
names(s) <- c('IDW', 'OK', 'TPS', 'Ensemble')
plot(s)
```


## Pregunta 7
**Show where the largest difference exist between IDW and OK**

```{r, echo=FALSE}
sa <- stack(idw, ok[[1]])
names(sa) <- c('IDW', 'OK')
plot(sa)

```

La mayor diferencia entre ambos mapas se concentra en la parte sur del estado, en donde el método de interpolación con pesos inversos da valores mayores de contaminación que usando el método de interpolación de Kringing.  

## Pregunta 8

**Show where the difference between IDW and OK is within the 95% confidence limit of the OK prediction.**

```{r}
k <- gstat(formula=OZDLYAV~1, locations=train, model=fve)
j<-gstat(formula=OZDLYAV~1, locations=train, model=idw)
# predicted values
k1 <- predict(k, g)

p<-(k1$var1.pred)
var<-sqrt(kp$var1.var)


li<-p-1.96*var
ls<-p+1.96*var

idm <- gstat(formula=OZDLYAV~1, locations=aq)
idp <- interpolate(r, idm)

j<-idp$var1.pred[1:9555]
a<-rep(0, 9555)
for(i in 1:9555){
if (j[i]<ls[i]&j[i]>li[i]) 
{
  a[i]<-1
}
}
summary (a)
```

Un 99% de los valores predichos del método de interpolación de pesos inversos caen dentro de los intervalos de confianza creados con los valores predichos del método de Kriging. 
Como se dijo en la pregunta anterior, las diferencias más importantes se encuentran en la zona del sur este, por lo que es probable que sea en esta región en donde se muestran la mayoría de los puntos que tienen una diferencia significativa entre los puntos.  

```{r, echo=FALSE}
sa <- stack(idw, ok[[1]])
names(sa) <- c('IDW', 'OK')
plot(sa)

```


Si construimos los mapas de los intervalos de confianza para OK, se puede observar con más detalle esta diferencia

```{r}
k2 <- brick(k1)

p1<-brick(k2$var1.pred) + sqrt(brick(k2$var1.var))*1.96
p2 <- mask(p1, ca)
p3<-brick(k2$var1.pred) - sqrt(brick(k2$var1.var))*1.96
p4 <- mask(p3, ca)
p5 <- stack(p4,p2, idw)
names(p5) <- c('L.inferior', 'L.superior' , "IDW")
plot(p5)


```

## Pregunta 9

**Can you describe the pattern we are seeing, and speculate about what is causing it?**

El patrón que se muestra se da en la región sureste del estado de California, precisamente en donde se encuentra el desierto de Arizona. Es esta región, por las características propias del lugar, se tienen mediciones que pueden considerarse extremas, por la calidad del aire que uno puede encontrar ahí. Por ese motivo, es que los métodos de interpolación pueden variar.


